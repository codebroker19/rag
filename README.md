1)Use codellama 7b<br>
2)Install the package on your visual studio code<br>
3)If there is problem in installation then maybe your internet provider is restricting it<br>
4)If that is the case use a VPN/mobile hotspot or change the DNS settings in your system<br>
5)pip install llama-cpp-python (check the official documentation also once)<br>
6)ollama serve<br>
7)ollama pull llama3<br>
8)from llama_cpp import Llama<br>
9)install streamlit<br>
10)use streamlit to run the application<br>
11)streamlit run file_name.py
